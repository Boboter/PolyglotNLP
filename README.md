# PolyglotNLP
PolyglotNLP: A Multilingual Language Detection Model Using spaCy and Machine Learning

This repository documents my journey of creating a language detection model that currently supports German, Russian, Italian, Portuguese, English, and Spanish, with the intention to expand to more languages. This project is meant as a learning project for myself.

## Project Overview

PolyglotNLP leverages datasets from Tatoeba, a rich source of sentences across numerous languages, to train a model capable of distinguishing between  German, Russian, Italian, Portuguese, English, and Spanish, texts. Through a process of data cleaning, normalization, tokenization, and vectorization, this project aims to build a model that not only identifies these languages with high accuracy but also sets the foundation for adding additional languages in the future.

## Features

- **Data Preprocessing**: Detailed steps for cleaning, normalizing, and tokenizing multilingual datasets.
- **Model Training and Evaluation**: Insight into training a Naive Bayes classifier with TfidfVectorizer for efficient language detection.
- **Expandability**: Designed with future enhancements in mind, making it easy to include more languages and improve the model's capabilities.
- **Testing Lab**: A sandbox environment for users to test the model's performance with their own sentences.

## Getting Started

Follow the instructions provided in this repository to set up the environment, download the datasets, and run the model on your local machine. Whether you're looking to expand the model to include more languages, improve its accuracy, or simply learn about NLP and machine learning, PolyglotNLP offers a solid foundation.

## License

This project is released under the MIT License. See the LICENSE file for more details.
